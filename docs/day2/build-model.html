<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayes, stat! - Building the model</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../day2/fit-model.html" rel="next">
<link href="../day2/setup.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Bayes, <em>stat</em>!</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../day1/learningobj.html">
 <span class="menu-text">Day 1</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../day2/learningobj.html" aria-current="page">
 <span class="menu-text">Day 2</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../resources.html">
 <span class="menu-text">Resources</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Building the model</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/learningobj.html" class="sidebar-item-text sidebar-link">Learning objectives</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/setup.html" class="sidebar-item-text sidebar-link">Getting set up</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/build-model.html" class="sidebar-item-text sidebar-link active">Building the model</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/fit-model.html" class="sidebar-item-text sidebar-link">Fitting and checking the model</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/report-model.html" class="sidebar-item-text sidebar-link">Interpreting and reporting model results</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../day2/day2-recap.html" class="sidebar-item-text sidebar-link">Day 2 Recap</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#anatomy-of-a-bayesian-model" id="toc-anatomy-of-a-bayesian-model" class="nav-link active" data-scroll-target="#anatomy-of-a-bayesian-model">Anatomy of a Bayesian model</a></li>
  <li><a href="#choosing-a-likelihood" id="toc-choosing-a-likelihood" class="nav-link" data-scroll-target="#choosing-a-likelihood">Choosing a likelihood</a>
  <ul class="collapse">
  <li><a href="#normal-gaussian" id="toc-normal-gaussian" class="nav-link" data-scroll-target="#normal-gaussian">Normal (Gaussian)</a></li>
  <li><a href="#log-normal" id="toc-log-normal" class="nav-link" data-scroll-target="#log-normal">Log-normal</a></li>
  <li><a href="#bernoulli" id="toc-bernoulli" class="nav-link" data-scroll-target="#bernoulli">Bernoulli</a></li>
  <li><a href="#other-likelihoods" id="toc-other-likelihoods" class="nav-link" data-scroll-target="#other-likelihoods">Other likelihoods</a></li>
  </ul></li>
  <li><a href="#begin-building-the-model" id="toc-begin-building-the-model" class="nav-link" data-scroll-target="#begin-building-the-model">Begin building the model</a></li>
  <li><a href="#choosing-priors" id="toc-choosing-priors" class="nav-link" data-scroll-target="#choosing-priors">Choosing priors</a>
  <ul class="collapse">
  <li><a href="#consider-order-of-magnitudemodel-space" id="toc-consider-order-of-magnitudemodel-space" class="nav-link" data-scroll-target="#consider-order-of-magnitudemodel-space">Consider order of magnitude/model space</a></li>
  <li><a href="#a-prior-for-alpha" id="toc-a-prior-for-alpha" class="nav-link" data-scroll-target="#a-prior-for-alpha">A prior for <span class="math inline">\(\alpha\)</span></a></li>
  <li><a href="#a-prior-for-the-betas" id="toc-a-prior-for-the-betas" class="nav-link" data-scroll-target="#a-prior-for-the-betas">A prior for the <span class="math inline">\(\beta\)</span>s</a></li>
  </ul></li>
  <li><a href="#summary-the-model-building-workflow" id="toc-summary-the-model-building-workflow" class="nav-link" data-scroll-target="#summary-the-model-building-workflow">Summary: The model-building workflow</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Building the model</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="anatomy-of-a-bayesian-model" class="level2">
<h2 class="anchored" data-anchor-id="anatomy-of-a-bayesian-model">Anatomy of a Bayesian model</h2>
<p>A Bayesian model combines the <strong>likelihood</strong> of the data, given different hypotheses, with the <strong>prior probabilities</strong> of those hypotheses, to give us the <strong>posterior probabilities</strong> of how probable different hypotheses are, given the data.</p>
<p>When we’re doing Bayesian inference, <strong>these hypotheses correspond to different parameter values</strong>: different values that the model’s coefficients can plausibly take on. The priors over these parameter values define how plausible we think different values are <em>a priori</em>. And the model will produce posteriors over the same parameter values that tell us what parameter values the model thinks are plausible, given the data.</p>
<p>But before we get to the posterior, we’ll need to define for our model a likelihood and some priors. We’ll start with the likelihood because it’s the closest part of the model to the outcome, so it’s the best starting point for figuring out a model that could plausibly have generated the outcome we observe. And it’ll also affect how our priors will look later.</p>
</section>
<section id="choosing-a-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="choosing-a-likelihood">Choosing a likelihood</h2>
<p>If you’ve done linear modelling before, you’ve probably already encountered this idea under the guise of the “model family”. If you know that you can fit a basic linear model to continuous outcome data, but that you need a binomial/Bernoulli/logistic model for binary outcome data, then you know how to choose a likelihood function.</p>
<p><strong>The likelihood function is selected based on the kinds of values that the outcome variable can take on.</strong> Here are three common examples.</p>
<section id="normal-gaussian" class="level3">
<h3 class="anchored" data-anchor-id="normal-gaussian">Normal (Gaussian)</h3>
<p>A continuous variable, such as formant values in Hz, can be said to follow a normal distribution (aka a Gaussian distribution). A normal distribution looks something like this:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/plot-gaus-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>So if we were modelling Hz, we would use a normal likelihood, and we could write it like this:</p>
<p><span class="math display">\[
Hz \sim Normal(\mu, \sigma)
\]</span></p>
<p><em>“Hz is distributed according to a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.”</em></p>
<p>(<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are parameters that define the distribution’s shape: where its mean is located, and how spread-out the distribution is around that mean, respectively.)</p>
<p>If you would use a basic linear model, not a generalised linear model, in your analysis, you would choose a Normal likelihood.</p>
</section>
<section id="log-normal" class="level3">
<h3 class="anchored" data-anchor-id="log-normal">Log-normal</h3>
<p>A continuous variable that’s positive-only and right-skewed, such as reaction times, might follow a normal distribution only once it’s been log-transformed. This means that, without any transformation, it follows a log-normal distribution.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/plot-lognorm-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>We write this as:</p>
<p><span class="math display">\[
RT \sim LogNormal(\mu, \sigma)
\]</span></p>
<p><em>“RT is distributed according to a lognormal distribution with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span>.”</em></p>
<p>Equivalently, one could log-transform RTs and model them with a normal likelihood:</p>
<p><span class="math display">\[
\log(RT) \sim Normal(\mu, \sigma)
\]</span></p>
<p>This is how it’s typically done in frequentist circles, but Bayesian models make it just as easy to use a lognormal likelihood as a normal one.</p>
</section>
<section id="bernoulli" class="level3">
<h3 class="anchored" data-anchor-id="bernoulli">Bernoulli</h3>
<p>If the outcome is binary (e.g., 0/1, success/failure, grammatical/ungrammatical, English/French, etc.), then we assume that it comes from a Bernoulli distribution defined by <span class="math inline">\(\theta\)</span>, the probability of success.</p>
<p><span class="math display">\[
success \sim Bernoulli(\theta)
\]</span></p>
<p><em>“Success is distributed according to a Bernoulli distribution with probability <span class="math inline">\(\theta\)</span>.”</em></p>
<p>Our model today will have a Bernoulli likelihood, since our data is binary: 0 if the participant rejected the sentence they saw, 1 if they accepted it.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Intuition: How can a probability produce binary outcomes?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Imagine a flip of a fair coin, where the probability of getting heads is <span class="math inline">\(\theta = 0.5\)</span>. In Bernoulli terms, the outcome representing “success” is generated with this probability <span class="math inline">\(\theta\)</span>, and the outcome representing “failure” is generated with probability <span class="math inline">\(1 - \theta\)</span>.</p>
<p>So, if you flip a fair coin ten times, you’ll get ten observations of binary outcomes (heads/tails), and probably about half of them will be heads (“success”).</p>
</div>
</div>
</div>
</section>
<section id="other-likelihoods" class="level3">
<h3 class="anchored" data-anchor-id="other-likelihoods">Other likelihoods</h3>
<p>Other likelihoods you may encounter include Poisson (for count data) or beta (for data in [0, 1]), and there are more besides. But for the usual analyses in experimental linguistics, the three above will be ones we reach for.</p>
</section>
</section>
<section id="begin-building-the-model" class="level2">
<h2 class="anchored" data-anchor-id="begin-building-the-model">Begin building the model</h2>
<p>Now that we have a likelihood, the next step is to think about what priors our model needs.</p>
<p>You saw that each of those likelihood functions above contains parameters that define their shape: <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\theta\)</span>. <strong>Every parameter in a Bayesian model needs to have a prior</strong> that tells the model which values are <em>a priori</em> plausible for that parameter to take on.</p>
<p>In this section, we build the model up bit by bit. This process will show us how many parameters our model has, and therefore what priors the model needs. We’ll start with the likelhood.</p>
<p>To build up the model, we’ll start off by defining the model’s likelihood.</p>
<p>We determined already which likelihood we need: acceptance <span class="math inline">\(acc\)</span> follows a Bernoulli distribution.</p>
<p><span class="math display">\[acc \sim Bernoulli(\theta)\]</span></p>
<p>We’re interested in modelling what affects <span class="math inline">\(\theta\)</span>, the probability of accepting a sentence. In other words, we want <span class="math inline">\(\theta\)</span> to be able to take on different values, depending on the condition participants were in and what kinds of sentences they were seeing. <span class="math inline">\(\theta\)</span> should be high in a certain situation if participants are more likely to accept sentences, and it should be low in another situation if they are more likely to reject them.</p>
<p>OK, well, more precisely: we actually want <span class="math inline">\(logit(\theta)\)</span>, the <em>log-odds</em> of accepting a sentence, to be able to take on different values. Converting probabilities (bounded between 0 and 1) into log-odds (unbounded) moves our estimation into a continuous space in which a line, also a continuous thing, can reasonably be fit.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What are log-odds and why do we use them?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>You’ve probably heard sayings like “What are the odds?”</p>
<p>We use the term “odds” colloquially, but it also has a formal definition in statistics:</p>
<p><span class="math display">\[
\text{odds} = \frac{\text{probability of a thing happening}}{\text{probability of the thing not happening}} = \frac{p}{1-p}
\]</span> Odds can be &gt; 1 (if <span class="math inline">\(p\)</span> &gt; 0.5) or &lt; 1 (if <span class="math inline">\(p\)</span> &lt; 0.5), but they cannot be negative. However, we want a scale that can take on positive <em>or</em> negative values, giving us a continuous space to fit a line in.</p>
<p>If we take the log of the odds, this effectively “unsquishes” the region in [0, 1], mapping it to (<span class="math inline">\(-\infty\)</span>, 0].</p>
<p>So, log-odds are a transformation of probabilities from [0, 1] into the range (<span class="math inline">\(-\infty\)</span>, <span class="math inline">\(\infty\)</span>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/p-log-odds-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>In a linear modelling approach, we allow <span class="math inline">\(logit(\theta)\)</span> to take on different values depending on the values of our predictors (<span class="math inline">\(cond\)</span> for condition, <span class="math inline">\(sent\)</span> for sentence) and their interaction (<span class="math inline">\(cond \cdot sent\)</span>) by setting it equal to this linear expression:</p>
<p><span class="math display">\[
logit(\theta) = \alpha + (\beta_1 \cdot cond) + (\beta_2 \cdot sent) + (\beta_3 \cdot cond \cdot sent)
\]</span></p>
<p>There’s a lot of Greek here! <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, and <span class="math inline">\(\beta_3\)</span> are the parameters that we want our model to estimate. You might recognise <span class="math inline">\(\alpha\)</span> as the line’s intercept, and all the <span class="math inline">\(\beta\)</span>s are the slopes, aka the effects, aka the coefficients of our predictors. We will need priors for all of these parameters.</p>
<p><strong>The priors will tell the model which values for each parameter we think are plausible, and they do this by describing how these parameter values are distributed.</strong> So, formally(ish), we’ll end up with a model that looks like this:</p>
<p><span class="math display">\[
\begin{aligned}
\text{acc} &amp; \sim Bernoulli(\theta) \\
logit(\theta) &amp; = \alpha + (\beta_1 \cdot cond) + (\beta_2 \cdot sent) + (\beta_3 \cdot cond \cdot sent)\\
\alpha &amp; \sim \text{something} \\
\beta_1 &amp; \sim \text{something} \\
\beta_2 &amp; \sim \text{something} \\
\beta_3 &amp; \sim \text{something} \\
\end{aligned}
\]</span></p>
<p>Finding suitable “something”s is the focus of the next section.</p>
</section>
<section id="choosing-priors" class="level2">
<h2 class="anchored" data-anchor-id="choosing-priors">Choosing priors</h2>
<p>There is a <em>lot</em> of literature on how to choose appropriate priors, and many different schools of thought.</p>
<p>Different kinds of priors you might encounter:</p>
<ul>
<li><strong>Informative priors:</strong> Priors that are quite narrow, reflecting more <em>a priori</em> certainty about the values that we believe to be plausible. These priors might come from, e.g.:
<ul>
<li>Domain knowledge elicited from experts.</li>
<li>Effect size estimates from one’s own previous research or from meta-analyses.</li>
</ul></li>
<li><strong>Weakly regularising priors:</strong> Priors that are fairly broad, reflecting <em>a priori</em> uncertainty about plausible parameter values. They rule out impossibly large values (e.g., RTs in the millions), but are uncertain enough that the data has much more of an influence on the posterior than they do.</li>
<li><strong>brms’ default priors:</strong> If you don’t specify any priors when you fit your model, brms will use its defaults. (You can see what these are with the command <code>brms::get_priors(mymodel)</code>.)</li>
</ul>
<p>I personally prefer to use weakly regularising priors, because (a) there often isn’t lots of domain knowledge available for the kinds of studies I’m running, and (b) weaker priors are less philosophically alarming to researchers trained in frequentism, and these are generally the people who review our papers.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Cromwell’s Rule
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This general preference for more liberal, less restrictive priors is also known as Cromwell’s Rule. The Cromwell in question is Oliver Cromwell, an English general who led a campaign against the Scottish army in 1650 and, in a letter to the Church of Scotland, wrote, “I beseech you, in the bowels of Christ, consider it possible that you are mistaken” (Jackman, 2009: 18). Lindley (1985), who named the rule, did so because wider priors allow us this possibility.</p>
<p><strong>References:</strong></p>
<p>Jackman, S. (2009). <em>Bayesian analysis for the social sciences.</em> London: John Wiley &amp; Sons, Ltd.</p>
<p>Lindley, D. V. (1985). <em>Making decisions.</em> 2nd ed.&nbsp;London: John Wiley &amp; Sons, Ltd.</p>
</div>
</div>
</div>
<p>Let’s walk through how to come up with weakly regularising priors for <span class="math inline">\(\alpha\)</span> and the <span class="math inline">\(\beta\)</span>s in the model above.</p>
<section id="consider-order-of-magnitudemodel-space" class="level3">
<h3 class="anchored" data-anchor-id="consider-order-of-magnitudemodel-space">Consider order of magnitude/model space</h3>
<p><strong>TLDR: Your priors must match the order of magnitude of the space the model is fit in.</strong></p>
<p>If the model’s coefficient estimates are interpretable using the same units as the outcome (e.g., if you’re using a normal likelihood), then we can say that the model is “fit in the outcome space”. If your model is fit in the outcome space, then you’ll need to think about what <strong>order of magnitude</strong> your outcome variable has.</p>
<ul>
<li>For example, if your outcome is raw reaction time, then your effects might be in the hundreds (of milliseconds).</li>
<li>But if your outcome is <em>log</em> reaction time, then your effects are probably in the single digits (of log units).</li>
</ul>
<p>A weak prior on the log scale is an incredibly restrictive prior on the millisecond scale. So the prior has to match the order of magnitude of the outcome.</p>
<p>If the model is <em>not</em> fit in the outcome space—i.e., if the outcome is transformed into a different space, and then the linear model is fit there—we need to know what space the model is fit in. This is because <strong>the priors have to be on the transformed scale,</strong> not the outcome scale.</p>
<p>In our case, our model transforms probabilities into log-odds, and then the linear expression is fit in log-odds space. That means our priors have to be <strong>on the log-odds scale</strong>.</p>
</section>
<section id="a-prior-for-alpha" class="level3">
<h3 class="anchored" data-anchor-id="a-prior-for-alpha">A prior for <span class="math inline">\(\alpha\)</span></h3>
<p><span class="math inline">\(\alpha\)</span> represents the intercept of our linear model. It is the outcome, in log-odds space, when all predictors equal zero. Because we’ll code up our predictors with <span class="math inline">\(\pm\)</span> 0.5 sum coding, our <span class="math inline">\(\alpha\)</span> represents the grand mean of the outcome.</p>
<p>Our goal: to come up with a weakly regularising prior that allows the outcome’s grand mean to take on basically any value. And for the intercept in particular, it’s useful to consider how this prior translates to probability space.</p>
<p>Let’s have a look at three different log-odds priors (in the left panels), and how they look once back-transformed into probability space (right panels). The higher the probability density, the more plausible the model will consider those values to be.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/alpha-prior-plots-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/alpha-prior-plots-2.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/alpha-prior-plots-3.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
ggplot code to generate those plots
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Here’s the function that generates these log-odds vs.&nbsp;probability plots, if you want to have a play yourself:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>plot_logodds_to_prob <span class="ot">&lt;-</span> <span class="cf">function</span>(logodds_data, distrib_str){</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># logodds_data: vector of numbers in log-odds space</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># distrib_str: a string description of the log-odds distribution (for plot title)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  facet_labels <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">log_odds =</span> <span class="st">'In log-odds space'</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob     =</span> <span class="st">'In probability space'</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">log_odds =</span> logodds_data) <span class="sc">%&gt;%</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">prob =</span> <span class="fu">plogis</span>(log_odds)) <span class="sc">%&gt;%</span> </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="st">'scale'</span>, <span class="at">values_to =</span> <span class="st">'sim'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>sim)) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span> scale, <span class="at">scales =</span> <span class="st">'free'</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>               <span class="at">labeller =</span> <span class="fu">as_labeller</span>(facet_labels)) <span class="sc">+</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_density</span>(<span class="at">fill=</span><span class="st">'grey'</span>, <span class="at">alpha=</span>.<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">title =</span> <span class="fu">paste</span>(</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        distrib_str, </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'in log-odds space and transformed to probability space'</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">'Probability density'</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>          <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>          <span class="at">panel.grid =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cn">NULL</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_logodds_to_prob</span>(<span class="fu">rnorm</span>(<span class="dv">100000</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="st">'Normal(0, 2)'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>What looks like an unassuming normal distribution in log-odds space can get pretty wacky in probability space. If we used <span class="math inline">\(\alpha \sim\)</span> Normal(0, 2), then the model would think that probabilities of success near 0 and 1 are more plausible than probabilities around 0.5. And if we used <span class="math inline">\(\alpha \sim\)</span> Normal(0, 1), then the model would think that those same extreme probabilities are very implausible, compared to the more moderate values. What we want is something in between.</p>
<p>When Normal(0, 1.5) is transformed into probability space, it yields a decently uniform distribution: basically any probability of success is <em>a priori</em> equally plausible.</p>
<p>We like this permissiveness, so this will be our prior for <span class="math inline">\(\alpha\)</span>. Our model becomes:</p>
<p><span class="math display">\[
\begin{aligned}
\text{acc} &amp; \sim Bernoulli(\theta) \\
logit(\theta) &amp; = \alpha + (\beta_1 \cdot cond) + (\beta_2 \cdot sent) + (\beta_3 \cdot cond \cdot sent)\\
\alpha &amp; \sim Normal(0, 1.5) \\
\beta_1 &amp; \sim \text{something} \\
\beta_2 &amp; \sim \text{something} \\
\beta_3 &amp; \sim \text{something} \\
\end{aligned}
\]</span></p>
</section>
<section id="a-prior-for-the-betas" class="level3">
<h3 class="anchored" data-anchor-id="a-prior-for-the-betas">A prior for the <span class="math inline">\(\beta\)</span>s</h3>
<p>The <span class="math inline">\(\beta\)</span>s represent the effects of interest—the main effects of <span class="math inline">\(cond\)</span> and <span class="math inline">\(sent\)</span>, and the effect of their interaction—in log-odds space. Note: I generally use the same weakly regularising prior for all the <span class="math inline">\(\beta\)</span>s, especially if they’re all on the same scale or coded the same way.</p>
<p>We found a decent prior for the intercept, <span class="math inline">\(\alpha\)</span>, by considering the mapping from log-odds to probability space. <strong>There’s no direct mapping for the <span class="math inline">\(\beta\)</span>s in the same way.</strong> This is because the <span class="math inline">\(\beta\)</span>s are added to the intercept in log-odds space; they never surface directly into the outcome space themselves, so it doesn’t make sense to think of them in terms of probabilities.</p>
<p>That <span class="math inline">\(\beta\)</span>s don’t stand alone makes it a bit harder to reason about what priors are sensible. How do we get around this? Enter <strong>prior predictive checks</strong>.</p>
<section id="prior-predictive-checks-in-brms" class="level4">
<h4 class="anchored" data-anchor-id="prior-predictive-checks-in-brms">Prior predictive checks in brms</h4>
<p>The basic idea is that we can capitalise on Bayesian models’ capacity as generative models to check whether different priors generate sensible data.</p>
<p>We tried it out for ourselves yesterday. But luckily, brms automates this for us!</p>
<p>We’ll set up models with a few different priors and use them to generate simulated data. Then we’ll look at that simulated data and see whether it looks fair. For us, “fair” means not too restricted—we want permissive priors (see Cromwell’s Rule above). This process is called “prior prediction” or “doing prior predictive checks”. (We’ll also do “posterior predictive checks” after fitting the model—stay tuned.)</p>
<p>Here’s the basic template for how to set up a prior predictive model in brms using the function <code>brm()</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mymodel <span class="ot">&lt;-</span> <span class="fu">brm</span>(myoutcome <span class="sc">~</span> mypredictor <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> mygroup),</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> mydata,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">family =</span> <span class="fu">bernoulli</span>(),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">prior</span>(SOMETHING, <span class="at">class =</span> b)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>               ),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">backend =</span> <span class="st">'cmdstanr'</span>,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">sample_prior =</span> <span class="st">'only'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>The first argument is the model formula in <code>lme4</code> syntax.</li>
<li>The <code>data=</code> argument names the data frame where the data to analyse can be found.</li>
<li>The <code>family=</code> argument defines the model family (<code>bernoulli()</code>, <code>gaussian()</code>, etc.).</li>
<li>The <code>prior=</code> argument defines the priors that the model will use. If there is no <code>prior=</code> argument, the model will use the default priors.</li>
<li>The line <code>backend = 'cmdstanr'</code> argument specifies that the model will be fit using CmdStan.</li>
<li>The line <code>sample_prior = 'only'</code> is what makes this model into a <em>prior</em> predictive model: it ignores the data and uses only the priors to estimate the posteriors (basically just reproducing the priors). Removing this line will cause the model to take the data into account when estimating posteriors, and we’ll do this when we properly fit the model.</li>
</ul>
<p><strong>Copy and adapt the template above</strong> to fit a prior predictive model with the formula <code>sentence_accepted ~ cond + sent + condsent</code> and the very-wide prior <code>normal(0, 10)</code> for <code>class = b</code> (“b” stands for “beta”), using data from <code>acc</code>. Name the model <code>priorpred10</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>priorpred10 <span class="ot">&lt;-</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Bayesian hierarchical models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In an IRL version of this analysis, we’d of course also include group-level effects (what frequentists call “random effects”). For ease of exposition, we’ll skip those for now and just treat all data points as independent.</p>
<p>If you want to learn how to do hierarchical models in a Bayesian framework, see, e.g., <a href="https://vasishth.github.io/bayescogsci/book/ch-hierarchical.html">here</a>. It’s essentially the same as what you’re used to, with the addition of a few more priors.</p>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">

</div>
<p>This model will estimate posteriors that reproduce the priors, ignoring the data, so that we can use these posteriors to generate some new data and see whether it look reasonable.</p>
<p>Generating predictive data is such a common thing to do that brms comes with a useful function that helps us do it graphically: <code>pp_check()</code> (documentation <a href="https://paul-buerkner.github.io/brms/reference/pp_check.brmsfit.html">here</a>).</p>
<p>Using your model <code>priorpred10</code>, run the following code. Here’s what the arguments we pass to <code>pp_check()</code> mean:</p>
<ul>
<li><code>type = 'stat'</code> is one possible type of plot generated by <code>pp_check()</code>. It applies some summary statistic to the generated data.</li>
<li><code>stat = mean</code> says that our summary statistic is going to be the function <code>mean()</code>.</li>
<li><code>prefix = 'ppd'</code> hides the observed data, which is shown by default, displaying only the predictive distributions (“ppd” = “prior predictive distribution”). It doesn’t make sense to include the data in the plot, because our prior predictive model didn’t take it into account.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(priorpred10,      </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">'stat'</span>,    </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">stat =</span> mean,      </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">prefix =</span> <span class="st">'ppd'</span>) <span class="sc">+</span> </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">'theta'</span>,        <span class="co"># We can add the usual layers to the ggplot object!</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">'Prior predictive distribution means with beta ~ Normal(0, 10)'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>This plot is telling us that the mean probability of success (i.e., of accepting a sentence) in the prior predictive distributions is nearly always around 0.5, and it’s <em>very</em> unlikely to have probabilities of success above or below that. This doesn’t look so great—we want a much broader and more even spread of means in the data that our model generates. Why? Because we want our model to be equally compatible with many different outcomes, not incredibly specific like this one is.</p>
<p>So let’s try a few more priors. Adapt the code above to fit a few more prior predictive models using these priors:</p>
<ul>
<li><span class="math inline">\(\beta \sim Normal(0, 5)\)</span></li>
<li><span class="math inline">\(\beta \sim Normal(0, 2)\)</span></li>
<li><span class="math inline">\(\beta \sim Normal(0, 1)\)</span></li>
<li><span class="math inline">\(\beta \sim Normal(0, 0.1)\)</span></li>
</ul>
<p>(and any others you want to try!)</p>
<p>For each model, generate a summary histogram using <code>pp_check()</code>, and then have a think about the following questions:</p>
<ul>
<li>Which of these priors produces the most even-looking distribution of outcome means?</li>
<li>Is that the prior we’ll want to use?</li>
<li>What effect sizes do each of these priors consider reasonable?</li>
</ul>
<p>Once you’ve gathered your own thoughts, uncollapse this box to have a look at mine:</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Prior predictive distributions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="build-model_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>When choosing between these priors, we need to balance our desires for an even spread of plausible values and for a reasonable effect size.</strong></p>
<p>The spread, perhaps counterintuitively, is most even with the narrowest prior, <span class="math inline">\(Normal(0, 0.1)\)</span>. But 95% of the plausible values in this prior fall within the range of about [–0.2, 0.2] log-odds—that’s nothing!</p>
<p>If we move one step broader and consider <span class="math inline">\(Normal(0, 1)\)</span>, we still have a decently uniform spread of prior predictive means, and now 95% of plausible effect sizes are between [–2, 2] log-odds. That’s better. (Intuitions about reasonable effect sizes are built through experience. If you don’t have them yet, don’t worry, you’ll get there!)</p>
<p>Finally, the broader priors permit a wide range of effect sizes, but they produce increasingly skewed distributions of predictive means, so we’ll stick with <span class="math inline">\(Normal(0, 1)\)</span>.</p>
<p><strong>Thus, our final model is:</strong></p>
<p><span class="math display">\[
\begin{aligned}
\text{acc} &amp; \sim Bernoulli(\theta) \\
logit(\theta) &amp; = \alpha + (\beta_1 \cdot cond) + (\beta_2 \cdot sent) + (\beta_3 \cdot cond \cdot sent)\\
\alpha &amp; \sim Normal(0, 1.5) \\
\beta_1 &amp; \sim Normal(0, 1) \\
\beta_2 &amp; \sim Normal(0, 1) \\
\beta_3 &amp; \sim Normal(0, 1) \\
\end{aligned}
\]</span></p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="summary-the-model-building-workflow" class="level2">
<h2 class="anchored" data-anchor-id="summary-the-model-building-workflow">Summary: The model-building workflow</h2>
<ol type="1">
<li><p>Find a <strong>likelihood</strong> suitable for the outcome data.</p></li>
<li><p>Identify the <strong>parameters</strong> required by the likelihood and by the line you want to fit.</p></li>
<li><p>Use prior predictive checks to find plausible <strong>priors</strong> for each of those parameters.</p></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../day2/setup.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Getting set up</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../day2/fit-model.html" class="pagination-link">
        <span class="nav-page-text">Fitting and checking the model</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>