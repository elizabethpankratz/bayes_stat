---
title: "Day 1 Recap"
---

**How are beliefs about the world formalised?**

- As probability distributions over the possible values that the parameter in question could take on.

**How do different priors influence a model's estimates?**

- Models with uninformative priors learn more from the data than do models with informative priors.
- But as the amount of data grows, the influence of the prior wanes.

**How do we interpret a posterior probability distribution?**

- It tells us how probable each possible parameter value is, given the data and the priors.
- The 95% Credible Interval gives us the range in which the model is 95% certain that the true value lies.

**How does the model find the posterior distribution?**

- brms models use an algorithm called Markov Chain Monte Carlo to approximate the posterior by drawing many samples from it.

**How do Bayesian models generate data?**

- The likelihood's parameter values can be sampled from the prior distributions.
- And then we sample from the likelihood to generate one data point.
